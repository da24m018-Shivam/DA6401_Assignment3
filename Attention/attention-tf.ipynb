{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "267c1d25",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-20T21:53:46.403785Z",
     "iopub.status.busy": "2025-05-20T21:53:46.402975Z",
     "iopub.status.idle": "2025-05-20T21:53:53.116235Z",
     "shell.execute_reply": "2025-05-20T21:53:53.114983Z"
    },
    "papermill": {
     "duration": 6.722116,
     "end_time": "2025-05-20T21:53:53.117982",
     "exception": false,
     "start_time": "2025-05-20T21:53:46.395866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-20 21:53:46--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.64.207, 74.125.126.207, 142.251.184.207, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.64.207|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2008340480 (1.9G) [application/x-tar]\r\n",
      "Saving to: ‘dakshina_dataset_v1.0.tar’\r\n",
      "\r\n",
      "dakshina_dataset_v1 100%[===================>]   1.87G   301MB/s    in 6.5s    \r\n",
      "\r\n",
      "2025-05-20 21:53:53 (295 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac4a7d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:53:53.152184Z",
     "iopub.status.busy": "2025-05-20T21:53:53.151385Z",
     "iopub.status.idle": "2025-05-20T21:53:55.715312Z",
     "shell.execute_reply": "2025-05-20T21:53:55.714071Z"
    },
    "papermill": {
     "duration": 2.574011,
     "end_time": "2025-05-20T21:53:55.717022",
     "exception": false,
     "start_time": "2025-05-20T21:53:53.143011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -xf dakshina_dataset_v1.0.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82159017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:53:55.766667Z",
     "iopub.status.busy": "2025-05-20T21:53:55.766362Z",
     "iopub.status.idle": "2025-05-20T21:54:12.355023Z",
     "shell.execute_reply": "2025-05-20T21:54:12.354357Z"
    },
    "papermill": {
     "duration": 16.59647,
     "end_time": "2025-05-20T21:54:12.356184",
     "exception": false,
     "start_time": "2025-05-20T21:53:55.759714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivam-da24m018\u001b[0m (\u001b[33mshivam-da24m018-iitmaana\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"93b4881869bab13360839595daa56e51dd0405df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62752c80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:12.368496Z",
     "iopub.status.busy": "2025-05-20T21:54:12.368099Z",
     "iopub.status.idle": "2025-05-20T21:54:29.821922Z",
     "shell.execute_reply": "2025-05-20T21:54:29.820971Z"
    },
    "papermill": {
     "duration": 17.461298,
     "end_time": "2025-05-20T21:54:29.823227",
     "exception": false,
     "start_time": "2025-05-20T21:54:12.361929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 21:54:13.804929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747778053.997865      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747778054.057877      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPU(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_random_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_random_seeds()\n",
    "\n",
    "# Check for GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Using {len(gpus)} GPU(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0ae8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:29.836800Z",
     "iopub.status.busy": "2025-05-20T21:54:29.836218Z",
     "iopub.status.idle": "2025-05-20T21:54:29.843517Z",
     "shell.execute_reply": "2025-05-20T21:54:29.842695Z"
    },
    "papermill": {
     "duration": 0.015525,
     "end_time": "2025-05-20T21:54:29.844820",
     "exception": false,
     "start_time": "2025-05-20T21:54:29.829295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the code from config.py\n",
    "DEFAULT_CONFIG = {\n",
    "    'cell_type': 'GRU',\n",
    "    'embed_size': 128,\n",
    "    'hidden_size': 256,\n",
    "    'encoder_layers': 1,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.0005,\n",
    "    'teacher_forcing_ratio': 0.5,\n",
    "    'attention_type': 'dot',\n",
    "    'clip_norm': 5.0,\n",
    "    'epochs': 1\n",
    "}\n",
    "\n",
    "def calculate_model_complexity(embedding_size, hidden_size, sequence_length, vocabulary_size):\n",
    "    \"\"\"\n",
    "    Calculate model complexity\n",
    "    Parameters:\n",
    "        embedding_size: Size of embedding vectors\n",
    "        hidden_size: Size of hidden state\n",
    "        sequence_length: Maximum sequence length\n",
    "        vocabulary_size: Size of vocabulary\n",
    "    \"\"\"\n",
    "    # Embedding layer parameters\n",
    "    embedding_params = 2 * vocabulary_size * embedding_size  # Source and target embeddings\n",
    "    \n",
    "    # RNN parameters (for both encoder and decoder)\n",
    "    encoder_rnn_params = embedding_size * hidden_size + hidden_size * hidden_size + hidden_size  # Input-to-hidden, hidden-to-hidden, bias\n",
    "    decoder_rnn_params = embedding_size * hidden_size + hidden_size * hidden_size + hidden_size\n",
    "    \n",
    "    # Output layer parameters\n",
    "    output_params = hidden_size * vocabulary_size + vocabulary_size  # Hidden-to-output, bias\n",
    "    \n",
    "    # Total parameters\n",
    "    total_params = embedding_params + encoder_rnn_params + decoder_rnn_params + output_params\n",
    "    \n",
    "    # Computations\n",
    "    # Encoder computations\n",
    "    encoder_comp = sequence_length * (embedding_size * hidden_size + hidden_size * hidden_size)\n",
    "    \n",
    "    # Decoder computations\n",
    "    decoder_comp = sequence_length * (embedding_size * hidden_size + hidden_size * hidden_size + hidden_size * vocabulary_size)\n",
    "    \n",
    "    # Total computations\n",
    "    total_comp = encoder_comp + decoder_comp\n",
    "    \n",
    "    return {\n",
    "        'embedding_params': embedding_params,\n",
    "        'encoder_rnn_params': encoder_rnn_params,\n",
    "        'decoder_rnn_params': decoder_rnn_params,\n",
    "        'output_params': output_params,\n",
    "        'total_params': total_params,\n",
    "        'encoder_comp': encoder_comp,\n",
    "        'decoder_comp': decoder_comp,\n",
    "        'total_comp': total_comp\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e84393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:29.857724Z",
     "iopub.status.busy": "2025-05-20T21:54:29.857442Z",
     "iopub.status.idle": "2025-05-20T21:54:29.938496Z",
     "shell.execute_reply": "2025-05-20T21:54:29.937496Z"
    },
    "papermill": {
     "duration": 0.089341,
     "end_time": "2025-05-20T21:54:29.940060",
     "exception": false,
     "start_time": "2025-05-20T21:54:29.850719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the code from data_utils.py\n",
    "class TransliterationDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, source_tensor, target_tensor, batch_size=64, shuffle=True):\n",
    "        self.source_tensor = source_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.source_tensor))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_tensor) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return self.source_tensor[batch_indices], self.target_tensor[batch_indices]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "def load_corpus(filepath):\n",
    "    \"\"\"Extract transliteration pairs from corpus file\"\"\"\n",
    "    corpus_entries = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as corpus_file:\n",
    "        for entry in corpus_file:\n",
    "            segments = entry.strip().split('\\t')\n",
    "            if len(segments) >= 2:\n",
    "                roman_text = segments[1]\n",
    "                native_text = segments[0]\n",
    "                corpus_entries.append((roman_text, native_text))\n",
    "    return corpus_entries\n",
    "\n",
    "def create_vocabulary(corpus_entries):\n",
    "    \"\"\"Generate character-to-index mappings from corpus\"\"\"\n",
    "    roman_character_set = set()\n",
    "    native_character_set = set()\n",
    "    \n",
    "    for roman_text, native_text in corpus_entries:\n",
    "        roman_character_set.update(roman_text)\n",
    "        native_character_set.update(native_text)\n",
    "    \n",
    "    print(\"Sample native script chars:\", sorted(native_character_set)[:10])\n",
    "    print(\"Sample roman script chars:\", sorted(roman_character_set)[:10])\n",
    "    \n",
    "    # Add special tokens\n",
    "    special_tokens = ['<pad>', '<sos>', '<eos>']\n",
    "    for token in special_tokens:\n",
    "        roman_character_set.add(token)\n",
    "        native_character_set.add(token)\n",
    "    \n",
    "    # Create dictionaries\n",
    "    roman_to_idx = {char: idx for idx, char in enumerate(sorted(roman_character_set))}\n",
    "    idx_to_roman = {idx: char for char, idx in roman_to_idx.items()}\n",
    "    \n",
    "    native_to_idx = {char: idx for idx, char in enumerate(sorted(native_character_set))}\n",
    "    idx_to_native = {idx: char for char, idx in native_to_idx.items()}\n",
    "    \n",
    "    return roman_to_idx, idx_to_roman, native_to_idx, idx_to_native\n",
    "\n",
    "def encode_sequences(corpus_entries, roman_to_idx, native_to_idx, max_roman_len=None, max_native_len=None):\n",
    "    \"\"\"Convert character sequences to index sequences\"\"\"\n",
    "    if max_roman_len is None:\n",
    "        max_roman_len = max(len(roman) for roman, _ in corpus_entries) + 2  # +2 for <sos> and <eos>\n",
    "    \n",
    "    if max_native_len is None:\n",
    "        max_native_len = max(len(native) for _, native in corpus_entries) + 2\n",
    "    \n",
    "    roman_sequences = []\n",
    "    native_sequences = []\n",
    "    \n",
    "    for roman_text, native_text in corpus_entries:\n",
    "        # Process roman text\n",
    "        roman_indices = [roman_to_idx['<sos>']]\n",
    "        roman_indices.extend(roman_to_idx[char] for char in roman_text)\n",
    "        roman_indices.append(roman_to_idx['<eos>'])\n",
    "        \n",
    "        # Pad roman sequence\n",
    "        padding_length = max_roman_len - len(roman_indices)\n",
    "        roman_indices.extend([roman_to_idx['<pad>']] * padding_length)\n",
    "        roman_sequences.append(roman_indices)\n",
    "        \n",
    "        # Process native text\n",
    "        native_indices = [native_to_idx['<sos>']]\n",
    "        native_indices.extend(native_to_idx[char] for char in native_text)\n",
    "        native_indices.append(native_to_idx['<eos>'])\n",
    "        \n",
    "        # Pad native sequence\n",
    "        padding_length = max_native_len - len(native_indices)\n",
    "        native_indices.extend([native_to_idx['<pad>']] * padding_length)\n",
    "        native_sequences.append(native_indices)\n",
    "    \n",
    "    return np.array(roman_sequences), np.array(native_sequences), max_roman_len, max_native_len\n",
    "\n",
    "def prepare_data_pipeline(corpus_dir, batch_size=64):\n",
    "    \"\"\"Setup complete data pipeline for training and evaluation\"\"\"\n",
    "    train_corpus = load_corpus(os.path.join(corpus_dir, 'hi.translit.sampled.train.tsv'))\n",
    "    dev_corpus = load_corpus(os.path.join(corpus_dir, 'hi.translit.sampled.dev.tsv'))\n",
    "    test_corpus = load_corpus(os.path.join(corpus_dir, 'hi.translit.sampled.test.tsv'))\n",
    "    \n",
    "    # Build character mappings from training and validation data\n",
    "    roman_to_idx, idx_to_roman, native_to_idx, idx_to_native = create_vocabulary(train_corpus + dev_corpus)\n",
    "    \n",
    "    # Transform data to indices\n",
    "    X_train, y_train, max_roman_len, max_native_len = encode_sequences(\n",
    "        train_corpus, roman_to_idx, native_to_idx)\n",
    "    \n",
    "    X_dev, y_dev, _, _ = encode_sequences(\n",
    "        dev_corpus, roman_to_idx, native_to_idx, max_roman_len, max_native_len)\n",
    "    \n",
    "    X_test, y_test, _, _ = encode_sequences(\n",
    "        test_corpus, roman_to_idx, native_to_idx, max_roman_len, max_native_len)\n",
    "    \n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(batch_size)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_dev, y_dev)).batch(batch_size)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n",
    "    \n",
    "    return {\n",
    "        'train_dataset': train_dataset,\n",
    "        'val_dataset': val_dataset,\n",
    "        'test_dataset': test_dataset,\n",
    "        'roman_to_idx': roman_to_idx,\n",
    "        'idx_to_roman': idx_to_roman,\n",
    "        'native_to_idx': native_to_idx,\n",
    "        'idx_to_native': idx_to_native,\n",
    "        'max_roman_len': max_roman_len,\n",
    "        'max_native_len': max_native_len\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fb3524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:29.953732Z",
     "iopub.status.busy": "2025-05-20T21:54:29.953462Z",
     "iopub.status.idle": "2025-05-20T21:54:29.984079Z",
     "shell.execute_reply": "2025-05-20T21:54:29.983396Z"
    },
    "papermill": {
     "duration": 0.039026,
     "end_time": "2025-05-20T21:54:29.985451",
     "exception": false,
     "start_time": "2025-05-20T21:54:29.946425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the code from model.py\n",
    "class AttentionMechanism(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, method='dot'):\n",
    "        super(AttentionMechanism, self).__init__()\n",
    "        self.units = units\n",
    "        self.method = method.lower()\n",
    "        \n",
    "        if self.method == 'bahdanau':\n",
    "            # Bahdanau attention (additive)\n",
    "            self.W1 = tf.keras.layers.Dense(units)\n",
    "            self.W2 = tf.keras.layers.Dense(units)\n",
    "            self.V = tf.keras.layers.Dense(1)\n",
    "        # No parameters needed for Luong attention (multiplicative)\n",
    "    \n",
    "    def call(self, query, values):\n",
    "        # query shape: [batch_size, hidden_size]\n",
    "        # values shape: [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        if self.method == 'bahdanau':\n",
    "            # Bahdanau attention\n",
    "            # Expand query to [batch_size, 1, hidden_size]\n",
    "            query_expanded = tf.expand_dims(query, 1)\n",
    "            \n",
    "            # Calculate score\n",
    "            score = self.V(tf.nn.tanh(self.W1(query_expanded) + self.W2(values)))\n",
    "            \n",
    "            # Remove the last dimension\n",
    "            score = tf.squeeze(score, axis=-1)\n",
    "        else:\n",
    "            # Luong attention (multiplicative)\n",
    "            # Reshape query to [batch_size, hidden_size, 1]\n",
    "            query_reshaped = tf.expand_dims(query, -1)\n",
    "            \n",
    "            # Calculate score: [batch_size, seq_len, 1]\n",
    "            score = tf.matmul(values, query_reshaped)\n",
    "            \n",
    "            # Remove the last dimension\n",
    "            score = tf.squeeze(score, axis=-1)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # Calculate context vector\n",
    "        context = tf.matmul(tf.expand_dims(attention_weights, 1), values)\n",
    "        context = tf.squeeze(context, axis=1)\n",
    "        \n",
    "        return context, attention_weights\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units, cell_type='gru', num_layers=1, dropout_rate=0.0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type.lower()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # RNN layers\n",
    "        self.rnn_cells = []\n",
    "        for i in range(num_layers):\n",
    "            if self.cell_type == 'lstm':\n",
    "                cell = tf.keras.layers.LSTM(\n",
    "                    hidden_units,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    dropout=dropout_rate if i < num_layers-1 else 0.0,\n",
    "                    recurrent_initializer='glorot_uniform'\n",
    "                )\n",
    "            elif self.cell_type == 'gru':\n",
    "                cell = tf.keras.layers.GRU(\n",
    "                    hidden_units,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    dropout=dropout_rate if i < num_layers-1 else 0.0,\n",
    "                    recurrent_initializer='glorot_uniform'\n",
    "                )\n",
    "            else:  # Simple RNN\n",
    "                cell = tf.keras.layers.SimpleRNN(\n",
    "                    hidden_units,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    dropout=dropout_rate if i < num_layers-1 else 0.0,\n",
    "                    recurrent_initializer='glorot_uniform'\n",
    "                )\n",
    "            self.rnn_cells.append(cell)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        # x shape: [batch_size, seq_len]\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "        # Process through RNN layers\n",
    "        states = []\n",
    "        for i, rnn_cell in enumerate(self.rnn_cells):\n",
    "            if self.cell_type == 'lstm':\n",
    "                x, state_h, state_c = rnn_cell(x, training=training)\n",
    "                states.append([state_h, state_c])\n",
    "            else:\n",
    "                x, state = rnn_cell(x, training=training)\n",
    "                states.append(state)\n",
    "        \n",
    "        return x, states\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units, cell_type='gru',\n",
    "                 num_layers=1, dropout_rate=0.0, attention_type='dot'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type.lower()\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = AttentionMechanism(hidden_units, attention_type)\n",
    "        \n",
    "        # RNN layers\n",
    "        self.rnn_cells = []\n",
    "        for i in range(num_layers):\n",
    "            if self.cell_type == 'lstm':\n",
    "                cell = tf.keras.layers.LSTM(\n",
    "                    hidden_units,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    dropout=dropout_rate if i < num_layers-1 else 0.0,\n",
    "                    recurrent_initializer='glorot_uniform'\n",
    "                )\n",
    "            elif self.cell_type == 'gru':\n",
    "                cell = tf.keras.layers.GRU(\n",
    "                    hidden_units,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    dropout=dropout_rate if i < num_layers-1 else 0.0,\n",
    "                    recurrent_initializer='glorot_uniform'\n",
    "                )\n",
    "            else:  # Simple RNN\n",
    "                cell = tf.keras.layers.SimpleRNN(\n",
    "                    hidden_units,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    dropout=dropout_rate if i < num_layers-1 else 0.0,\n",
    "                    recurrent_initializer='glorot_uniform'\n",
    "                )\n",
    "            self.rnn_cells.append(cell)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, hidden, encoder_output, training=False):\n",
    "        # x shape: [batch_size]\n",
    "        # hidden shape: list of states for each layer\n",
    "        # encoder_output shape: [batch_size, seq_len, hidden_units]\n",
    "        \n",
    "        # Get the last hidden state\n",
    "        if self.cell_type == 'lstm':\n",
    "            query = hidden[-1][0]  # Use hidden state, not cell state\n",
    "        else:\n",
    "            query = hidden[-1]\n",
    "        \n",
    "        # Calculate attention\n",
    "        context, attention_weights = self.attention(query, encoder_output)\n",
    "        \n",
    "        # Expand x to [batch_size, 1]\n",
    "        x = tf.expand_dims(x, 1)\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # [batch_size, 1, embedding_dim]\n",
    "        \n",
    "        # Concatenate context vector and embedding\n",
    "        x = tf.concat([tf.expand_dims(context, 1), x], axis=-1)\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        # Process through RNN layers\n",
    "        new_hidden = []\n",
    "        for i, rnn_cell in enumerate(self.rnn_cells):\n",
    "            if i > 0:\n",
    "                x = self.dropout(x, training=training)\n",
    "            \n",
    "            if self.cell_type == 'lstm':\n",
    "                current_hidden = hidden[i]\n",
    "                x, state_h, state_c = rnn_cell(x, initial_state=current_hidden, training=training)\n",
    "                new_hidden.append([state_h, state_c])\n",
    "            else:\n",
    "                current_hidden = hidden[i]\n",
    "                x, state = rnn_cell(x, initial_state=current_hidden, training=training)\n",
    "                new_hidden.append(state)\n",
    "        \n",
    "        # Output\n",
    "        x = self.fc(tf.concat([x[:, 0], context], axis=-1))\n",
    "        \n",
    "        return x, new_hidden, attention_weights\n",
    "\n",
    "class Seq2SeqModel(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, start_token_idx, end_token_idx):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.start_token_idx = start_token_idx\n",
    "        self.end_token_idx = end_token_idx\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "    # This method explicitly builds the model\n",
    "    # input_shape is a tuple of (source_shape, target_shape)\n",
    "        source_shape, target_shape = input_shape\n",
    "        \n",
    "        # Build encoder\n",
    "        self.encoder.build(source_shape)\n",
    "        \n",
    "        # Build decoder - create a dummy state to help build it\n",
    "        dummy_source = tf.zeros((1,) + source_shape[1:], dtype=tf.int32)\n",
    "        dummy_encoder_output, dummy_states = self.encoder(dummy_source)\n",
    "        \n",
    "        # Build decoder with dummy inputs\n",
    "        dummy_decoder_input = tf.zeros((1,), dtype=tf.int32)\n",
    "        \n",
    "        # Check if we're using LSTM (which returns a list of [state_h, state_c] for each layer)\n",
    "        if isinstance(dummy_states[0], list):\n",
    "            # For LSTM, use the hidden state (state_h)\n",
    "            state_shape = dummy_states[0][0].shape\n",
    "        else:\n",
    "            # For GRU or RNN, use the state directly\n",
    "            state_shape = dummy_states[0].shape\n",
    "            \n",
    "        self.decoder.build([(1,), state_shape, dummy_encoder_output.shape])\n",
    "    \n",
    "        self.built = True\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        # Unpack inputs\n",
    "        source, target = inputs\n",
    "        batch_size = tf.shape(source)[0]\n",
    "        target_length = tf.shape(target)[1]\n",
    "        \n",
    "        # Encode the source sequence\n",
    "        encoder_output, encoder_states = self.encoder(source, training=training)\n",
    "        \n",
    "        # Initialize output tensor - make sure it has the right shape\n",
    "        outputs = tf.TensorArray(tf.float32, size=target_length-1)\n",
    "        \n",
    "        # Prepare decoder input and states\n",
    "        decoder_input = tf.fill([batch_size], self.start_token_idx)\n",
    "        decoder_states = encoder_states\n",
    "        \n",
    "        # Teacher forcing ratio\n",
    "        teacher_forcing_ratio = 0.5 if training else 0.0\n",
    "        \n",
    "        # Decode step by step - start from position 1 (after start token)\n",
    "        for t in range(1, target_length):\n",
    "            # Get output from decoder\n",
    "            prediction, decoder_states, _ = self.decoder(\n",
    "                decoder_input, decoder_states, encoder_output, training=training)\n",
    "            \n",
    "            # Store prediction\n",
    "            outputs = outputs.write(t-1, prediction)\n",
    "            \n",
    "            # Teacher forcing\n",
    "            if training and tf.random.uniform([]) < teacher_forcing_ratio:\n",
    "                decoder_input = target[:, t]\n",
    "            else:\n",
    "                decoder_input = tf.argmax(prediction, axis=1)\n",
    "        \n",
    "        # Stack outputs - ensure it has the right shape to match target\n",
    "        outputs = tf.transpose(outputs.stack(), [1, 0, 2])\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def translate(self, source, max_length=50):\n",
    "        \"\"\"\n",
    "        Translate source sequences to target sequences\n",
    "        Args:\n",
    "            source: Source sequence tensor [batch_size, seq_len]\n",
    "            max_length: Maximum length of generated sequence\n",
    "        Returns:\n",
    "            translations: Generated sequences [batch_size, seq_len]\n",
    "            attention_weights: Attention weights for visualization [batch_size, tgt_len, src_len]\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(source)[0]\n",
    "        \n",
    "        # Encode the source sequence\n",
    "        encoder_output, encoder_states = self.encoder(source, training=False)\n",
    "        \n",
    "        # Prepare decoder input and states\n",
    "        decoder_input = tf.fill([batch_size], self.start_token_idx)\n",
    "        decoder_states = encoder_states\n",
    "        \n",
    "        # Initialize result tensors - specify int32 dtype\n",
    "        translations = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
    "        attention_weights_array = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "        \n",
    "        # Store first token (start token)\n",
    "        translations = translations.write(0, decoder_input)\n",
    "        \n",
    "        for t in range(1, max_length):\n",
    "            # Get output from decoder\n",
    "            prediction, decoder_states, attention_weights = self.decoder(\n",
    "                decoder_input, decoder_states, encoder_output, training=False)\n",
    "            \n",
    "            # Get predicted token and cast to int32\n",
    "            predicted_id = tf.argmax(prediction, axis=1)\n",
    "            predicted_id = tf.cast(predicted_id, tf.int32)  # Cast to int32\n",
    "            \n",
    "            # Store results\n",
    "            translations = translations.write(t, predicted_id)\n",
    "            attention_weights_array = attention_weights_array.write(t-1, attention_weights)\n",
    "            \n",
    "            # Break if end token is predicted for all sequences in batch\n",
    "            if tf.reduce_all(tf.equal(predicted_id, self.end_token_idx)):\n",
    "                break\n",
    "            \n",
    "            # Use predicted token as next input\n",
    "            decoder_input = predicted_id\n",
    "        \n",
    "        # Stack results\n",
    "        translations = tf.transpose(translations.stack())  # [batch_size, seq_len]\n",
    "        attention_weights = tf.transpose(attention_weights_array.stack(), [1, 0, 2])  # [batch_size, tgt_len, src_len]\n",
    "        \n",
    "        return translations, attention_weights\n",
    "\n",
    "def create_model(source_vocab_size, target_vocab_size, embedding_dim=256, hidden_units=512,\n",
    "                 cell_type='gru', num_layers=2, dropout_rate=0.1, attention_type='dot',\n",
    "                 start_token_idx=0, end_token_idx=1):\n",
    "    encoder = Encoder(\n",
    "        source_vocab_size, embedding_dim, hidden_units,\n",
    "        cell_type, num_layers, dropout_rate\n",
    "    )\n",
    "    \n",
    "    decoder = Decoder(\n",
    "        target_vocab_size, embedding_dim, hidden_units,\n",
    "        cell_type, num_layers, dropout_rate, attention_type\n",
    "    )\n",
    "    \n",
    "    model = Seq2SeqModel(encoder, decoder, start_token_idx, end_token_idx)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d60b3b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:29.998890Z",
     "iopub.status.busy": "2025-05-20T21:54:29.998594Z",
     "iopub.status.idle": "2025-05-20T21:54:30.016756Z",
     "shell.execute_reply": "2025-05-20T21:54:30.016002Z"
    },
    "papermill": {
     "duration": 0.026452,
     "end_time": "2025-05-20T21:54:30.018015",
     "exception": false,
     "start_time": "2025-05-20T21:54:29.991563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the code from train.py\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        return self.initial_learning_rate\n",
    "\n",
    "def train_step(model, source, target, optimizer, loss_function, clip_norm):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        predictions = model((source, target), training=True)\n",
    "        \n",
    "        # Get actual batch size from the current batch\n",
    "        batch_size = tf.shape(source)[0]\n",
    "        \n",
    "        # Reshape for loss calculation\n",
    "        target_seq = target[:, 1:]  # Exclude start token\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_function(target_seq, predictions)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    # Clip gradients\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, clip_norm)\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return tf.reduce_mean(loss)  # Return scalar loss\n",
    "\n",
    "def validation_step(model, source, target, loss_function):\n",
    "    \"\"\"Evaluate model on validation data\"\"\"\n",
    "    # Forward pass (no teacher forcing)\n",
    "    predictions = model((source, target), training=False)\n",
    "    \n",
    "    # Reshape for loss calculation\n",
    "    target_seq = target[:, 1:]  # Exclude start token\n",
    "    predictions_seq = predictions  # Already aligned in model\n",
    "    \n",
    "    # Calculate loss\n",
    "    mask = tf.math.logical_not(tf.math.equal(target_seq, 0))  # 0 is pad token\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    loss = loss_function(target_seq, predictions_seq, sample_weight=mask)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(model, dataset, target_to_idx, idx_to_target, idx_to_source):\n",
    "    \"\"\"Calculate word-level accuracy\"\"\"\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    prediction_details = []\n",
    "    \n",
    "    # Find special tokens\n",
    "    start_token_idx = target_to_idx['<sos>']\n",
    "    end_token_idx = target_to_idx['<eos>']\n",
    "    pad_token_idx = target_to_idx['<pad>']\n",
    "    \n",
    "    for source_batch, target_batch in tqdm(dataset, desc=\"Computing accuracy\"):\n",
    "        batch_size = tf.shape(source_batch)[0]\n",
    "        \n",
    "        # Translate\n",
    "        translations, attention_weights = model.translate(source_batch)\n",
    "        \n",
    "        # Process each example in batch\n",
    "        for i in range(batch_size):\n",
    "            # Extract source sequence\n",
    "            source_seq = []\n",
    "            for j in range(tf.shape(source_batch)[1]):\n",
    "                idx = source_batch[i, j].numpy()\n",
    "                if idx in idx_to_source and idx_to_source[idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                    source_seq.append(idx_to_source[idx])\n",
    "            \n",
    "            # Extract prediction and target sequences\n",
    "            pred_seq = []\n",
    "            target_seq = []\n",
    "            \n",
    "            # Process prediction\n",
    "            for j in range(tf.shape(translations)[1]):\n",
    "                pred_idx = translations[i, j].numpy()\n",
    "                if pred_idx == end_token_idx or pred_idx == pad_token_idx:\n",
    "                    break\n",
    "                if pred_idx in idx_to_target and idx_to_target[pred_idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                    pred_seq.append(idx_to_target[pred_idx])\n",
    "            \n",
    "            # Process target\n",
    "            for j in range(1, tf.shape(target_batch)[1]):  # Skip start token\n",
    "                target_idx = target_batch[i, j].numpy()\n",
    "                if target_idx == end_token_idx or target_idx == pad_token_idx:\n",
    "                    break\n",
    "                if target_idx in idx_to_target and idx_to_target[target_idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                    target_seq.append(idx_to_target[target_idx])\n",
    "            \n",
    "            # Convert to strings\n",
    "            pred_word = ''.join(pred_seq)\n",
    "            target_word = ''.join(target_seq)\n",
    "            source_word = ''.join(source_seq)\n",
    "            \n",
    "            # Get attention weights\n",
    "            attn_matrix = attention_weights[i, :len(pred_seq), :len(source_seq)].numpy()\n",
    "            \n",
    "            # Store prediction details\n",
    "            prediction_details.append({\n",
    "                'source': source_word,\n",
    "                'prediction': pred_word,\n",
    "                'target': target_word,\n",
    "                'attention': attn_matrix\n",
    "            })\n",
    "            \n",
    "            # Update accuracy\n",
    "            if pred_word == target_word:\n",
    "                correct_predictions += 1\n",
    "            total_samples += 1\n",
    "    \n",
    "    accuracy = correct_predictions / total_samples if total_samples > 0 else 0\n",
    "    return accuracy, prediction_details\n",
    "\n",
    "def train_model(model, data_loaders, config):\n",
    "    # Setup optimizer and loss function\n",
    "    optimizer = tf.keras.optimizers.Adam(config['learning_rate'])\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config['epochs']):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for source_batch, target_batch in tqdm(data_loaders['train_dataset'], desc=f\"Epoch {epoch+1} Training\"):\n",
    "            # Get loss for this batch\n",
    "            batch_loss = train_step(\n",
    "                model, source_batch, target_batch, optimizer, loss_function, config['clip_norm']\n",
    "            )\n",
    "            \n",
    "            # Accumulate loss (use scalar value)\n",
    "            total_loss += float(batch_loss)\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Calculate average loss\n",
    "        train_loss = total_loss / num_batches\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss = 0\n",
    "        val_steps = 0\n",
    "        \n",
    "        for source_batch, target_batch in tqdm(data_loaders['val_dataset'], desc=\"Validation\"):\n",
    "            batch_loss = validation_step(\n",
    "                model,\n",
    "                source_batch,\n",
    "                target_batch,\n",
    "                loss_function\n",
    "            )\n",
    "            \n",
    "            val_loss += batch_loss\n",
    "            val_steps += 1\n",
    "        \n",
    "        val_loss = val_loss / val_steps\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy, _ = compute_accuracy(\n",
    "            model,\n",
    "            data_loaders['val_dataset'],\n",
    "            data_loaders['native_to_idx'],\n",
    "            data_loaders['idx_to_native'],\n",
    "            data_loaders['idx_to_roman']\n",
    "        )\n",
    "        \n",
    "        # Log metrics\n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': accuracy,\n",
    "        })\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'\\tTraining Loss: {train_loss:.3f}')\n",
    "        print(f'\\tValidation Loss: {val_loss:.3f}')\n",
    "        print(f'\\tAccuracy: {accuracy:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            model.save_weights('models/best-transliteration-model.weights.h5')\n",
    "            print(f'\\tNew best accuracy: {best_accuracy:.4f}, model saved')\n",
    "    \n",
    "    return best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f5e202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:30.031414Z",
     "iopub.status.busy": "2025-05-20T21:54:30.031040Z",
     "iopub.status.idle": "2025-05-20T21:54:30.050790Z",
     "shell.execute_reply": "2025-05-20T21:54:30.050114Z"
    },
    "papermill": {
     "duration": 0.027845,
     "end_time": "2025-05-20T21:54:30.052068",
     "exception": false,
     "start_time": "2025-05-20T21:54:30.024223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the code from test.py\n",
    "def evaluate_model(model, data_loaders):\n",
    "    \"\"\"Evaluate model on test set and analyze results\"\"\"\n",
    "    # Load best model weights\n",
    "    model.load_weights('models/best-transliteration-model.weights.h5')\n",
    "    \n",
    "    # Calculate accuracy and get predictions\n",
    "    test_accuracy, prediction_results = compute_test_accuracy(\n",
    "        model,\n",
    "        data_loaders['test_dataset'],\n",
    "        data_loaders['native_to_idx'],\n",
    "        data_loaders['idx_to_native'],\n",
    "        data_loaders['idx_to_roman']\n",
    "    )\n",
    "    \n",
    "    # Calculate character-level accuracy\n",
    "    char_accuracy = compute_character_accuracy(prediction_results)\n",
    "    \n",
    "    # Analyze error patterns\n",
    "    error_patterns = analyze_error_patterns(prediction_results)\n",
    "    \n",
    "    # Log metrics to wandb\n",
    "    wandb.log({\n",
    "        'test_word_accuracy': test_accuracy,\n",
    "        'test_char_accuracy': char_accuracy\n",
    "    })\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Test Word Accuracy: {test_accuracy:.4f}')\n",
    "    print(f'Test Character Accuracy: {char_accuracy:.4f}')\n",
    "    \n",
    "    # Print most common errors\n",
    "    print(\"\\nMost common error patterns:\")\n",
    "    for (target_char, pred_char), count in sorted(error_patterns.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"Target '{target_char}' predicted as '{pred_char}': {count} times\")\n",
    "    \n",
    "    # Log sample predictions\n",
    "    sample_entries = []\n",
    "    for i, pred in enumerate(prediction_results[:10]):\n",
    "        sample_entries.append([i, pred['prediction'], pred['target'], pred['prediction'] == pred['target']])\n",
    "    \n",
    "    wandb.log({\n",
    "        \"prediction_samples\": wandb.Table(\n",
    "            columns=[\"Index\", \"Prediction\", \"Target\", \"Correct\"],\n",
    "            data=sample_entries\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    # Create error analysis visualization\n",
    "    top_errors = sorted(error_patterns.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    error_labels = [f\"{t}->{p}\" for (t, p), _ in top_errors]\n",
    "    error_counts = [count for _, count in top_errors]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(error_labels, error_counts)\n",
    "    plt.xlabel('Error Type (Target->Prediction)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Top 10 Error Patterns')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Log visualization\n",
    "    wandb.log({\"error_analysis\": wandb.Image(plt)})\n",
    "    plt.close()\n",
    "    \n",
    "    return test_accuracy, prediction_results\n",
    "\n",
    "def compute_test_accuracy(model, dataset, target_to_idx, idx_to_target, idx_to_source):\n",
    "    \"\"\"Calculate accuracy on test set and collect detailed predictions\"\"\"\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Find special tokens\n",
    "    start_token_idx = target_to_idx['<sos>']\n",
    "    end_token_idx = target_to_idx['<eos>']\n",
    "    pad_token_idx = target_to_idx['<pad>']\n",
    "    \n",
    "    for source_batch, target_batch in tqdm(dataset, desc=\"Testing\"):\n",
    "        batch_size = tf.shape(source_batch)[0]\n",
    "        \n",
    "        # Translate\n",
    "        translations, attention_weights = model.translate(source_batch)\n",
    "        \n",
    "        # Process each example in batch\n",
    "        for i in range(batch_size):\n",
    "            # Extract source sequence\n",
    "            source_seq = []\n",
    "            for j in range(tf.shape(source_batch)[1]):\n",
    "                idx = source_batch[i, j].numpy()\n",
    "                if idx in idx_to_source and idx_to_source[idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                    source_seq.append(idx_to_source[idx])\n",
    "            \n",
    "            # Extract prediction and target sequences\n",
    "            pred_seq = []\n",
    "            target_seq = []\n",
    "            \n",
    "            # Process prediction\n",
    "            for j in range(tf.shape(translations)[1]):\n",
    "                pred_idx = translations[i, j].numpy()\n",
    "                if pred_idx == end_token_idx or pred_idx == pad_token_idx:\n",
    "                    break\n",
    "                if pred_idx in idx_to_target and idx_to_target[pred_idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                    pred_seq.append(idx_to_target[pred_idx])\n",
    "            \n",
    "            # Process target\n",
    "            for j in range(1, tf.shape(target_batch)[1]):  # Skip start token\n",
    "                target_idx = target_batch[i, j].numpy()\n",
    "                if target_idx == end_token_idx or target_idx == pad_token_idx:\n",
    "                    break\n",
    "                if target_idx in idx_to_target and idx_to_target[target_idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                    target_seq.append(idx_to_target[target_idx])\n",
    "            \n",
    "            # Convert to strings\n",
    "            pred_word = ''.join(pred_seq)\n",
    "            target_word = ''.join(target_seq)\n",
    "            source_word = ''.join(source_seq)\n",
    "            \n",
    "            # Get attention weights\n",
    "            attn_matrix = attention_weights[i, :len(pred_seq), :len(source_seq)].numpy()\n",
    "            \n",
    "            # Store prediction details\n",
    "            all_predictions.append({\n",
    "                'source': source_word,\n",
    "                'prediction': pred_word,\n",
    "                'target': target_word,\n",
    "                'attention': attn_matrix\n",
    "            })\n",
    "            \n",
    "            # Update accuracy counters\n",
    "            if pred_word == target_word:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "    \n",
    "    accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "    return accuracy, all_predictions\n",
    "\n",
    "def compute_character_accuracy(predictions):\n",
    "    \"\"\"Calculate character-level accuracy\"\"\"\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    \n",
    "    for pred in predictions:\n",
    "        prediction = pred['prediction']\n",
    "        target = pred['target']\n",
    "        \n",
    "        # Compare characters up to the length of the shorter string\n",
    "        min_len = min(len(prediction), len(target))\n",
    "        for i in range(min_len):\n",
    "            if prediction[i] == target[i]:\n",
    "                correct_chars += 1\n",
    "            total_chars += 1\n",
    "        \n",
    "        # Count remaining characters in longer string as errors\n",
    "        total_chars += abs(len(prediction) - len(target))\n",
    "    \n",
    "    char_accuracy = correct_chars / total_chars if total_chars > 0 else 0\n",
    "    return char_accuracy\n",
    "\n",
    "def analyze_error_patterns(predictions):\n",
    "    \"\"\"Analyze common error patterns in predictions\"\"\"\n",
    "    error_counter = Counter()\n",
    "    \n",
    "    for pred in predictions:\n",
    "        prediction = pred['prediction']\n",
    "        target = pred['target']\n",
    "        \n",
    "        if prediction != target:\n",
    "            # Find the first position where they differ\n",
    "            min_len = min(len(prediction), len(target))\n",
    "            for i in range(min_len):\n",
    "                if prediction[i] != target[i]:\n",
    "                    error_pair = (target[i], prediction[i])\n",
    "                    error_counter[error_pair] += 1\n",
    "                    break\n",
    "            \n",
    "            # Handle length differences\n",
    "            if len(prediction) != len(target) and min_len > 0 and i == min_len - 1:\n",
    "                if len(prediction) < len(target):\n",
    "                    error_pair = (target[min_len], \"MISSING\")\n",
    "                else:\n",
    "                    error_pair = (\"MISSING\", prediction[min_len])\n",
    "                error_counter[error_pair] += 1\n",
    "    \n",
    "    return error_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b44d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:30.066080Z",
     "iopub.status.busy": "2025-05-20T21:54:30.065809Z",
     "iopub.status.idle": "2025-05-20T21:54:30.080765Z",
     "shell.execute_reply": "2025-05-20T21:54:30.080074Z"
    },
    "papermill": {
     "duration": 0.023807,
     "end_time": "2025-05-20T21:54:30.082070",
     "exception": false,
     "start_time": "2025-05-20T21:54:30.058263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the code from visualize.py\n",
    "def render_attention_heatmap(attention_matrix, source_text, predicted_text, target_text, output_path=None):\n",
    "    \"\"\"Create a visualization of attention weights\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Convert attention to numpy if it's a tensor\n",
    "    if isinstance(attention_matrix, tf.Tensor):\n",
    "        attention_matrix = attention_matrix.numpy()\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(attention_matrix, ax=ax, cmap='viridis', cbar=True)\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax.set_xticklabels([''] + list(source_text), rotation=90)\n",
    "    ax.set_yticklabels([''] + list(predicted_text))\n",
    "    \n",
    "    # Set title\n",
    "    ax.set_title(f\"Target: {target_text}\")\n",
    "    \n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Save if path is provided\n",
    "    if output_path:\n",
    "        fig.savefig(output_path)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_attention_visualization_grid(prediction_results, sample_count=10, output_path='results/attention_grid.png'):\n",
    "    \"\"\"Create a grid of attention visualizations\"\"\"\n",
    "    # Limit to available examples\n",
    "    sample_count = min(sample_count, len(prediction_results))\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    grid_rows = 5\n",
    "    grid_cols = 2\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols*4, grid_rows*4))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < sample_count:\n",
    "            pred = prediction_results[i]\n",
    "            \n",
    "            # Get attention matrix\n",
    "            attention = pred['attention']\n",
    "            if isinstance(attention, tf.Tensor):\n",
    "                attention = attention.numpy()\n",
    "            \n",
    "            # Plot heatmap\n",
    "            sns.heatmap(attention, ax=ax, cmap='Blues', cbar=False)\n",
    "            \n",
    "            # Set tick positions and labels\n",
    "            source_chars = [''] + list(pred['source'])\n",
    "            prediction_chars = [''] + list(pred['prediction'])\n",
    "            \n",
    "            # Set x-ticks positions\n",
    "            ax.set_xticks(np.arange(len(source_chars)))\n",
    "            ax.set_xticklabels(source_chars, rotation=90)\n",
    "            \n",
    "            # Set y-ticks positions\n",
    "            ax.set_yticks(np.arange(len(prediction_chars)))\n",
    "            ax.set_yticklabels(prediction_chars)\n",
    "            \n",
    "            # Set title\n",
    "            ax.set_title(f\"Target: {pred['target']}\", fontsize=10)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create directory if needed\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def visualize_character_mappings(model, data_loaders, sample_count=5, output_dir='results/character_mappings'):\n",
    "    \"\"\"Visualize how characters are mapped between source and target\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get a batch of examples\n",
    "    for source_batch, target_batch in data_loaders['test_dataset'].take(1):\n",
    "        break\n",
    "    \n",
    "    # Process a few examples\n",
    "    for example_idx in range(min(sample_count, tf.shape(source_batch)[0])):\n",
    "        # Get single example\n",
    "        source_example = tf.expand_dims(source_batch[example_idx], 0)\n",
    "        \n",
    "        # Translate\n",
    "        translations, attention_weights = model.translate(source_example)\n",
    "        \n",
    "        # Extract source sequence\n",
    "        source_chars = []\n",
    "        for i in range(tf.shape(source_example)[1]):\n",
    "            idx = source_example[0, i].numpy()\n",
    "            if idx in data_loaders['idx_to_roman'] and data_loaders['idx_to_roman'][idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                source_chars.append(data_loaders['idx_to_roman'][idx])\n",
    "        \n",
    "        # Extract prediction\n",
    "        prediction_chars = []\n",
    "        for i in range(tf.shape(translations)[1]):\n",
    "            idx = translations[0, i].numpy()\n",
    "            if idx in data_loaders['idx_to_native'] and data_loaders['idx_to_native'][idx] not in ['<pad>', '<sos>', '<eos>']:\n",
    "                prediction_chars.append(data_loaders['idx_to_native'][idx])\n",
    "            if idx == data_loaders['native_to_idx']['<eos>']:\n",
    "                break\n",
    "        \n",
    "        # Create visualization\n",
    "        if len(prediction_chars) > 0 and len(source_chars) > 0:\n",
    "            attention_matrix = attention_weights[0, :len(prediction_chars), :len(source_chars)].numpy()\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.heatmap(attention_matrix, cmap='viridis', cbar=True)\n",
    "            plt.xticks(np.arange(len(source_chars)) + 0.5, source_chars, rotation=90)\n",
    "            plt.yticks(np.arange(len(prediction_chars)) + 0.5, prediction_chars)\n",
    "            plt.title(f\"Character Mapping: {''.join(source_chars)} → {''.join(prediction_chars)}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
    "            plt.close()\n",
    "    \n",
    "    print(f\"Character mapping visualizations saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe050e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:30.096063Z",
     "iopub.status.busy": "2025-05-20T21:54:30.095634Z",
     "iopub.status.idle": "2025-05-20T21:54:30.464236Z",
     "shell.execute_reply": "2025-05-20T21:54:30.463138Z"
    },
    "papermill": {
     "duration": 0.377259,
     "end_time": "2025-05-20T21:54:30.465644",
     "exception": false,
     "start_time": "2025-05-20T21:54:30.088385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: o7dpo2cj\n",
      "Sweep URL: https://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/sweeps/o7dpo2cj\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "\n",
    "sweep_config = {\n",
    "        'method': 'random',\n",
    "        'metric': {\n",
    "            'name': 'val_accuracy',\n",
    "            'goal': 'maximize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'cell_type': {\n",
    "                'values': ['RNN', 'LSTM', 'GRU']\n",
    "            },\n",
    "            'embed_size': {\n",
    "                'values': [32,64, 128, 256]\n",
    "            },\n",
    "            'hidden_size': {\n",
    "                'values': [64,128, 256, 512, 1024]\n",
    "            },\n",
    "            'encoder_layers': {\n",
    "                'values': [1, 2,3]\n",
    "            },\n",
    "            'dropout': {\n",
    "                'values': [0.1, 0.2, 0.3]\n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [32, 64, 128]\n",
    "            },\n",
    "            'learning_rate': {\n",
    "                'values': [0.001, 0.0005, 0.0001]\n",
    "            },\n",
    "            'teacher_forcing_ratio': {\n",
    "                'values': [0.3, 0.5, 0.7,0.9]\n",
    "            },\n",
    "            'attention_type': {\n",
    "                'values': ['bahdanau', 'dot']\n",
    "            },\n",
    "            'clip': {\n",
    "            'values': [1.0, 5.0]\n",
    "        },\n",
    "            'epochs': {\n",
    "                'values': [5, 10, 15,20] \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# Define the sweep configuration\n",
    "\n",
    "\n",
    "# Define the training function for the sweep\n",
    "def sweep_train(config=None):\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config):\n",
    "        # Access all hyperparameter values through wandb.config\n",
    "        config = wandb.config\n",
    "        \n",
    "        # Create directories\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "        \n",
    "        # Prepare data\n",
    "        data_loaders = prepare_data_pipeline('/kaggle/working/dakshina_dataset_v1.0/hi/lexicons/', batch_size=config.batch_size)\n",
    "        \n",
    "        # Initialize model\n",
    "        source_vocab_size = len(data_loaders['roman_to_idx'])\n",
    "        target_vocab_size = len(data_loaders['native_to_idx'])\n",
    "        \n",
    "        # Get special token indices\n",
    "        start_token_idx = data_loaders['native_to_idx']['<sos>']\n",
    "        end_token_idx = data_loaders['native_to_idx']['<eos>']\n",
    "        \n",
    "        model = create_model(\n",
    "            source_vocab_size=source_vocab_size,\n",
    "            target_vocab_size=target_vocab_size,\n",
    "            embedding_dim=config.embed_size,\n",
    "            hidden_units=config.hidden_size,\n",
    "            cell_type=config.cell_type,\n",
    "            num_layers=config.encoder_layers,\n",
    "            dropout_rate=config.dropout,\n",
    "            attention_type=config.attention_type,\n",
    "            start_token_idx=start_token_idx,\n",
    "            end_token_idx=end_token_idx\n",
    "        )\n",
    "        \n",
    "        # Calculate model complexity\n",
    "        complexity = calculate_model_complexity(\n",
    "            embedding_size=config.embed_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            sequence_length=max(data_loaders['max_roman_len'], data_loaders['max_native_len']),\n",
    "            vocabulary_size=max(source_vocab_size, target_vocab_size)\n",
    "        )\n",
    "        \n",
    "        # Log model complexity\n",
    "        wandb.log(complexity)\n",
    "        \n",
    "        # Create a config dictionary for training\n",
    "        train_config = {\n",
    "            'cell_type': config.cell_type,\n",
    "            'embed_size': config.embed_size,\n",
    "            'hidden_size': config.hidden_size,\n",
    "            'encoder_layers': config.encoder_layers,\n",
    "            'dropout': config.dropout,\n",
    "            'batch_size': config.batch_size,\n",
    "            'learning_rate': config.learning_rate,\n",
    "            'teacher_forcing_ratio': 0.5,\n",
    "            'attention_type': config.attention_type,\n",
    "            'clip_norm':config.clip,\n",
    "            'epochs': config.epochs  # Set a fixed number of epochs for the sweep\n",
    "        }\n",
    "        \n",
    "        # Train model\n",
    "        best_accuracy = train_model(model, data_loaders, train_config)\n",
    "        \n",
    "        # Evaluate model\n",
    "        test_accuracy, predictions = evaluate_model(model, data_loaders)\n",
    "        \n",
    "        # Create attention visualizations\n",
    "        create_attention_visualization_grid(predictions, sample_count=10, output_path='results/attention_grid.png')\n",
    "        \n",
    "        # Create character mapping visualizations\n",
    "        visualize_character_mappings(model, data_loaders, sample_count=5)\n",
    "        \n",
    "        # Log visualizations to wandb\n",
    "        wandb.log({\"attention_grid\": wandb.Image('results/attention_grid.png')})\n",
    "        \n",
    "        # Log character mapping visualizations\n",
    "        for i in range(5):\n",
    "            if os.path.exists(f'results/character_mappings/mapping_{i}.png'):\n",
    "                wandb.log({f\"character_mapping_{i}\": wandb.Image(f'results/character_mappings/mapping_{i}.png')})\n",
    "\n",
    "# Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"tf-transliteration-attention_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060c95c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:30.478853Z",
     "iopub.status.busy": "2025-05-20T21:54:30.478254Z",
     "iopub.status.idle": "2025-05-20T21:54:30.486025Z",
     "shell.execute_reply": "2025-05-20T21:54:30.485400Z"
    },
    "papermill": {
     "duration": 0.015701,
     "end_time": "2025-05-20T21:54:30.487321",
     "exception": false,
     "start_time": "2025-05-20T21:54:30.471620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run a single experiment with default parameters\n",
    "def run_single_experiment():\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=\"tf-transliteration-attention\", config=DEFAULT_CONFIG)\n",
    "    \n",
    "    # Get config\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Prepare data\n",
    "    data_loaders = prepare_data_pipeline('/kaggle/working/dakshina_dataset_v1.0/hi/lexicons/', batch_size=config.batch_size)\n",
    "    \n",
    "    # Initialize model\n",
    "    source_vocab_size = len(data_loaders['roman_to_idx'])\n",
    "    target_vocab_size = len(data_loaders['native_to_idx'])\n",
    "    \n",
    "    # Get special token indices\n",
    "    start_token_idx = data_loaders['native_to_idx']['<sos>']\n",
    "    end_token_idx = data_loaders['native_to_idx']['<eos>']\n",
    "    \n",
    "    model = create_model(\n",
    "        source_vocab_size=source_vocab_size,\n",
    "        target_vocab_size=target_vocab_size,\n",
    "        embedding_dim=config.embed_size,\n",
    "        hidden_units=config.hidden_size,\n",
    "        cell_type=config.cell_type,\n",
    "        num_layers=config.encoder_layers,\n",
    "        dropout_rate=config.dropout,\n",
    "        attention_type=config.attention_type,\n",
    "        start_token_idx=start_token_idx,\n",
    "        end_token_idx=end_token_idx\n",
    "    )\n",
    "    \n",
    "    # Calculate model complexity\n",
    "    complexity = calculate_model_complexity(\n",
    "        embedding_size=config.embed_size,\n",
    "        hidden_size=config.hidden_size,\n",
    "        sequence_length=max(data_loaders['max_roman_len'], data_loaders['max_native_len']),\n",
    "        vocabulary_size=max(source_vocab_size, target_vocab_size)\n",
    "    )\n",
    "    \n",
    "    # Log model complexity\n",
    "    wandb.log(complexity)\n",
    "    \n",
    "    # Train model\n",
    "    best_accuracy = train_model(model, data_loaders, config)\n",
    "    \n",
    "    # Evaluate model\n",
    "    test_accuracy, predictions = evaluate_model(model, data_loaders)\n",
    "    \n",
    "    # Create attention visualizations\n",
    "    create_attention_visualization_grid(predictions, sample_count=10, output_path='results/attention_grid.png')\n",
    "    \n",
    "    # Create character mapping visualizations\n",
    "    visualize_character_mappings(model, data_loaders, sample_count=5)\n",
    "    \n",
    "    # Log visualizations to wandb\n",
    "    wandb.log({\"attention_grid\": wandb.Image('results/attention_grid.png')})\n",
    "    \n",
    "    # Log character mapping visualizations\n",
    "    for i in range(5):\n",
    "        if os.path.exists(f'results/character_mappings/mapping_{i}.png'):\n",
    "            wandb.log({f\"character_mapping_{i}\": wandb.Image(f'results/character_mappings/mapping_{i}.png')})\n",
    "    \n",
    "    wandb.finish()\n",
    "\n",
    "# Uncomment to run a single experiment\n",
    "# run_single_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dc06ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T21:54:30.500419Z",
     "iopub.status.busy": "2025-05-20T21:54:30.500111Z"
    },
    "papermill": {
     "duration": 29430.563715,
     "end_time": "2025-05-21T06:05:01.057105",
     "exception": false,
     "start_time": "2025-05-20T21:54:30.493390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: roy0zg4v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_215431-roy0zg4v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdecent-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/sweeps/o7dpo2cj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/roy0zg4v\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample native script chars: ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ']\n",
      "Sample roman script chars: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747778073.621180      66 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1747778073.622035      66 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "Epoch 1 Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1747778078.378691     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'decoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "Epoch 1 Training: 100%|██████████| 691/691 [15:10<00:00,  1.32s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:36<00:00,  1.91it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:46<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 1.166\n",
      "\tValidation Loss: 0.891\n",
      "\tAccuracy: 0.0007\n",
      "\tNew best accuracy: 0.0007, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 691/691 [14:40<00:00,  1.27s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:34<00:00,  1.97it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:42<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.683\n",
      "\tValidation Loss: 0.522\n",
      "\tAccuracy: 0.1083\n",
      "\tNew best accuracy: 0.1083, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 691/691 [15:02<00:00,  1.31s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:34<00:00,  1.97it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:47<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.449\n",
      "\tValidation Loss: 0.459\n",
      "\tAccuracy: 0.1905\n",
      "\tNew best accuracy: 0.1905, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 691/691 [14:48<00:00,  1.29s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:34<00:00,  2.00it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:41<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.377\n",
      "\tValidation Loss: 0.425\n",
      "\tAccuracy: 0.2389\n",
      "\tNew best accuracy: 0.2389, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 691/691 [14:58<00:00,  1.30s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:35<00:00,  1.93it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:48<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.335\n",
      "\tValidation Loss: 0.387\n",
      "\tAccuracy: 0.2650\n",
      "\tNew best accuracy: 0.2650, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 691/691 [15:05<00:00,  1.31s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:36<00:00,  1.87it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:48<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.304\n",
      "\tValidation Loss: 0.387\n",
      "\tAccuracy: 0.2926\n",
      "\tNew best accuracy: 0.2926, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 691/691 [15:36<00:00,  1.36s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:37<00:00,  1.82it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:54<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.280\n",
      "\tValidation Loss: 0.368\n",
      "\tAccuracy: 0.3178\n",
      "\tNew best accuracy: 0.3178, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 691/691 [16:04<00:00,  1.40s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:38<00:00,  1.80it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:52<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.261\n",
      "\tValidation Loss: 0.368\n",
      "\tAccuracy: 0.3176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 691/691 [15:45<00:00,  1.37s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:38<00:00,  1.80it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:56<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.244\n",
      "\tValidation Loss: 0.358\n",
      "\tAccuracy: 0.3403\n",
      "\tNew best accuracy: 0.3403, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|██████████| 691/691 [15:51<00:00,  1.38s/it]\n",
      "Validation: 100%|██████████| 69/69 [00:37<00:00,  1.86it/s]\n",
      "Computing accuracy: 100%|██████████| 69/69 [02:52<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.233\n",
      "\tValidation Loss: 0.367\n",
      "\tAccuracy: 0.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 71/71 [02:57<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Word Accuracy: 0.3374\n",
      "Test Character Accuracy: 0.6718\n",
      "\n",
      "Most common error patterns:\n",
      "Target 'ट' predicted as 'त': 111 times\n",
      "Target 'ी' predicted as 'ि': 109 times\n",
      "Target 'ड' predicted as 'द': 103 times\n",
      "Target 'ा' predicted as 'र': 88 times\n",
      "Target 'ू' predicted as 'ु': 75 times\n",
      "Target 'ल' predicted as 'ा': 60 times\n",
      "Target 'ि' predicted as 'ी': 55 times\n",
      "Target 'न' predicted as 'ा': 50 times\n",
      "Target 'त' predicted as 'ट': 47 times\n",
      "Target 'र' predicted as 'ा': 43 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2337 (\\N{DEVANAGARI LETTER DDA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2337 (\\N{DEVANAGARI LETTER DDA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character mapping visualizations saved to results/character_mappings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_char_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_word_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_accuracy ▁▃▅▆▆▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_loss █▃▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp 726528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params 24704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params 8448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp 540672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params 24704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params 8514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_char_accuracy 0.67177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_word_accuracy 0.33741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp 1267200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params 66370\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_loss 0.23346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_accuracy 0.33433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_loss 0.3665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdecent-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/roy0zg4v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 8 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_215431-roy0zg4v/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 45ac53fr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250521_010508-45ac53fr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33matomic-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/sweeps/o7dpo2cj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/45ac53fr\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample native script chars: ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ']\n",
      "Sample roman script chars: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|          | 0/1382 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'decoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "Epoch 1 Training: 100%|██████████| 1382/1382 [27:34<00:00,  1.20s/it]\n",
      "Validation: 100%|██████████| 137/137 [01:03<00:00,  2.14it/s]\n",
      "Computing accuracy: 100%|██████████| 137/137 [04:06<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 1.035\n",
      "\tValidation Loss: 0.674\n",
      "\tAccuracy: 0.0165\n",
      "\tNew best accuracy: 0.0165, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 1382/1382 [26:58<00:00,  1.17s/it]\n",
      "Validation: 100%|██████████| 137/137 [01:04<00:00,  2.13it/s]\n",
      "Computing accuracy: 100%|██████████| 137/137 [03:58<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.540\n",
      "\tValidation Loss: 0.482\n",
      "\tAccuracy: 0.1579\n",
      "\tNew best accuracy: 0.1579, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 1382/1382 [27:58<00:00,  1.21s/it]\n",
      "Validation: 100%|██████████| 137/137 [01:08<00:00,  2.00it/s]\n",
      "Computing accuracy: 100%|██████████| 137/137 [04:09<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.410\n",
      "\tValidation Loss: 0.436\n",
      "\tAccuracy: 0.2196\n",
      "\tNew best accuracy: 0.2196, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 1382/1382 [26:44<00:00,  1.16s/it]\n",
      "Validation: 100%|██████████| 137/137 [01:02<00:00,  2.18it/s]\n",
      "Computing accuracy: 100%|██████████| 137/137 [03:55<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.354\n",
      "\tValidation Loss: 0.400\n",
      "\tAccuracy: 0.2538\n",
      "\tNew best accuracy: 0.2538, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 1382/1382 [25:45<00:00,  1.12s/it]\n",
      "Validation: 100%|██████████| 137/137 [01:05<00:00,  2.09it/s]\n",
      "Computing accuracy: 100%|██████████| 137/137 [03:59<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.316\n",
      "\tValidation Loss: 0.397\n",
      "\tAccuracy: 0.2770\n",
      "\tNew best accuracy: 0.2770, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 141/141 [03:58<00:00,  1.69s/it]\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2337 (\\N{DEVANAGARI LETTER DDA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2376 (\\N{DEVANAGARI VOWEL SIGN AI}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2337 (\\N{DEVANAGARI LETTER DDA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2376 (\\N{DEVANAGARI VOWEL SIGN AI}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Word Accuracy: 0.2923\n",
      "Test Character Accuracy: 0.6435\n",
      "\n",
      "Most common error patterns:\n",
      "Target 'ी' predicted as 'ि': 126 times\n",
      "Target 'ट' predicted as 'त': 110 times\n",
      "Target 'ा' predicted as 'र': 98 times\n",
      "Target 'ड' predicted as 'द': 72 times\n",
      "Target 'न' predicted as 'ा': 70 times\n",
      "Target 'त' predicted as 'ट': 65 times\n",
      "Target 'ु' predicted as 'ू': 61 times\n",
      "Target 'द' predicted as 'ड': 50 times\n",
      "Target 'ू' predicted as 'ु': 50 times\n",
      "Target 'ै' predicted as 'ा': 41 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character mapping visualizations saved to results/character_mappings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch ▁▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_char_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_word_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_accuracy ▁▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_loss █▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp 726528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params 24704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params 8448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp 540672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params 24704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params 8514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_char_accuracy 0.64352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_word_accuracy 0.29231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp 1267200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params 66370\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_loss 0.31632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_accuracy 0.27696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_loss 0.39708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33matomic-sweep-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/45ac53fr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 8 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250521_010508-45ac53fr/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sw35n7i9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250521_034957-sw35n7i9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33melated-sweep-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/sweeps/o7dpo2cj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/sw35n7i9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample native script chars: ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ']\n",
      "Sample roman script chars: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|          | 0/346 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'decoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "Epoch 1 Training: 100%|██████████| 346/346 [06:40<00:00,  1.16s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.61it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:02<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 1.107\n",
      "\tValidation Loss: 0.727\n",
      "\tAccuracy: 0.0119\n",
      "\tNew best accuracy: 0.0119, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 346/346 [06:43<00:00,  1.17s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.60it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:05<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.725\n",
      "\tValidation Loss: 0.556\n",
      "\tAccuracy: 0.0493\n",
      "\tNew best accuracy: 0.0493, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 346/346 [06:49<00:00,  1.18s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.60it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:06<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.593\n",
      "\tValidation Loss: 0.506\n",
      "\tAccuracy: 0.1000\n",
      "\tNew best accuracy: 0.1000, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 346/346 [07:00<00:00,  1.22s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:22<00:00,  1.53it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:10<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.524\n",
      "\tValidation Loss: 0.490\n",
      "\tAccuracy: 0.1425\n",
      "\tNew best accuracy: 0.1425, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 346/346 [06:57<00:00,  1.21s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.60it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:07<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.483\n",
      "\tValidation Loss: 0.474\n",
      "\tAccuracy: 0.1510\n",
      "\tNew best accuracy: 0.1510, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 346/346 [06:50<00:00,  1.19s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.66it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:05<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.458\n",
      "\tValidation Loss: 0.461\n",
      "\tAccuracy: 0.1661\n",
      "\tNew best accuracy: 0.1661, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 346/346 [06:55<00:00,  1.20s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.61it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.440\n",
      "\tValidation Loss: 0.455\n",
      "\tAccuracy: 0.1726\n",
      "\tNew best accuracy: 0.1726, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 346/346 [06:49<00:00,  1.18s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.59it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:07<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.424\n",
      "\tValidation Loss: 0.443\n",
      "\tAccuracy: 0.1911\n",
      "\tNew best accuracy: 0.1911, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 346/346 [07:00<00:00,  1.21s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:21<00:00,  1.60it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:08<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.407\n",
      "\tValidation Loss: 0.449\n",
      "\tAccuracy: 0.1872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|██████████| 346/346 [07:08<00:00,  1.24s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:22<00:00,  1.54it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:08<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.396\n",
      "\tValidation Loss: 0.442\n",
      "\tAccuracy: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 36/36 [02:11<00:00,  3.64s/it]\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2337 (\\N{DEVANAGARI LETTER DDA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/3946840059.py:60: UserWarning: Glyph 2376 (\\N{DEVANAGARI VOWEL SIGN AI}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2337 (\\N{DEVANAGARI LETTER DDA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2370 (\\N{DEVANAGARI VOWEL SIGN UU}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n",
      "/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2376 (\\N{DEVANAGARI VOWEL SIGN AI}) missing from current font.\n",
      "  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Word Accuracy: 0.1986\n",
      "Test Character Accuracy: 0.6020\n",
      "\n",
      "Most common error patterns:\n",
      "Target 'ी' predicted as 'ि': 107 times\n",
      "Target 'ट' predicted as 'त': 101 times\n",
      "Target 'ड' predicted as 'द': 99 times\n",
      "Target 'ा' predicted as 'र': 90 times\n",
      "Target 'ू' predicted as 'ु': 79 times\n",
      "Target 'त' predicted as 'ट': 64 times\n",
      "Target 'ि' predicted as 'ी': 62 times\n",
      "Target 'न' predicted as 'ा': 54 times\n",
      "Target 'ा' predicted as 'न': 49 times\n",
      "Target 'ै' predicted as 'ा': 46 times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:77: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:123: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n",
      "/tmp/ipykernel_19/2817130389.py:124: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  plt.savefig(f\"{output_dir}/mapping_{example_idx}.png\", dpi=300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character mapping visualizations saved to results/character_mappings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_char_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_word_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_accuracy ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_loss █▄▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp 7231488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params 295424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params 8448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp 6488064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params 295424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params 33858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_char_accuracy 0.60202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: test_word_accuracy 0.19858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp 13719552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params 633154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train_loss 0.39606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_accuracy 0.18977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val_loss 0.44223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33melated-sweep-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/sw35n7i9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 8 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250521_034957-sw35n7i9/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1z1yju4q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250521_052607-1z1yju4q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvaliant-sweep-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/sweeps/o7dpo2cj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/1z1yju4q\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample native script chars: ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ']\n",
      "Sample roman script chars: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'decoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "Epoch 1 Training:   0%|          | 0/691 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_19/2490096164.py\", line 111, in sweep_train\n",
      "    best_accuracy = train_model(model, data_loaders, train_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_19/2559846305.py\", line 135, in train_model\n",
      "    batch_loss = train_step(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_19/2559846305.py\", line 13, in train_step\n",
      "    predictions = model((source, target), training=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/tmp/ipykernel_19/3133810471.py\", line 245, in call\n",
      "    encoder_output, encoder_states = self.encoder(source, training=training)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_19/3133810471.py\", line 101, in call\n",
      "    x, state = rnn_cell(x, training=training)\n",
      "    ^^^^^^^^\n",
      "ValueError: Exception encountered when calling Encoder.call().\n",
      "\n",
      "\u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n",
      "\n",
      "Arguments received by Encoder.call():\n",
      "  • x=tf.Tensor(shape=(64, 22), dtype=int64)\n",
      "  • training=True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       decoder_comp 27439104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: decoder_rnn_params 1180672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   embedding_params 16896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       encoder_comp 25952256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: encoder_rnn_params 1180672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      output_params 67650\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         total_comp 53391360\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       total_params 2445890\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvaliant-sweep-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/1z1yju4q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250521_052607-1z1yju4q/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1z1yju4q errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_19/2490096164.py\", line 111, in sweep_train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     best_accuracy = train_model(model, data_loaders, train_config)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_19/2559846305.py\", line 135, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     batch_loss = train_step(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                  ^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_19/2559846305.py\", line 13, in train_step\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     predictions = model((source, target), training=True)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise e.with_traceback(filtered_tb) from None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_19/3133810471.py\", line 245, in call\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     encoder_output, encoder_states = self.encoder(source, training=training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_19/3133810471.py\", line 101, in call\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x, state = rnn_cell(x, training=training)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m ValueError: Exception encountered when calling Encoder.call().\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \u001b[1mtoo many values to unpack (expected 2)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Arguments received by Encoder.call():\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • x=tf.Tensor(shape=(64, 22), dtype=int64)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   • training=True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kym2o7to with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250521_052612-kym2o7to\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/sweeps/o7dpo2cj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/shivam-da24m018-iitmaana/tf-transliteration-attention_2/runs/kym2o7to\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample native script chars: ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ']\n",
      "Sample roman script chars: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 346/346 [11:08<00:00,  1.93s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:27<00:00,  1.26it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:22<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 1.196\n",
      "\tValidation Loss: 0.988\n",
      "\tAccuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 346/346 [11:14<00:00,  1.95s/it]\n",
      "Validation: 100%|██████████| 35/35 [00:28<00:00,  1.21it/s]\n",
      "Computing accuracy: 100%|██████████| 35/35 [02:29<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Loss: 0.942\n",
      "\tValidation Loss: 0.833\n",
      "\tAccuracy: 0.0034\n",
      "\tNew best accuracy: 0.0034, model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training:  87%|████████▋ | 300/346 [10:26<07:31,  9.81s/it]"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=sweep_train, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef3a13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29481.401934,
   "end_time": "2025-05-21T06:05:03.040979",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-20T21:53:41.639045",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
